{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f3753d4",
   "metadata": {},
   "source": [
    "# Attempt to remap variables to MIP tables\n",
    "\n",
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fab0028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "from collections import defaultdict\n",
    "from copy import copy, deepcopy\n",
    "import shutil\n",
    "import hashlib\n",
    "\n",
    "# Add dreqPy v01.00.33 to path\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join(os.environ['HOME'], 'CDDS/dreq/dreq_versions/01.00.33/'))\n",
    "from dreqPy import dreq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222102d4",
   "metadata": {},
   "source": [
    "Specify directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b674a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP6_LOCATION = os.path.join(os.environ['HOME'], 'CDDS/github/cmip6-cmor-tables/Tables')\n",
    "OUTPUT_LOCATION = '../../Tables'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a285b2c2",
   "metadata": {},
   "source": [
    "Load miptables into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9974c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mip_tables_list = os.listdir(CMIP6_LOCATION)\n",
    "# Ignore non-mip table files\n",
    "for i in ['CMIP6_CV.json', 'CMIP6_coordinate.json', 'CMIP6_formula_terms.json',\n",
    "          'CMIP6_grids.json', 'CMIP6_input_example.json']:\n",
    "    mip_tables_list.remove(i)\n",
    "\n",
    "    \n",
    "# Read variable data into a dictionary structure ignore header for the moment.\n",
    "mip_tables_data = {}\n",
    "\n",
    "for mip_table_name in mip_tables_list:\n",
    "    with open(os.path.join(CMIP6_LOCATION, mip_table_name)) as handle:\n",
    "        table_data = json.load(handle)\n",
    "        table_name = table_data['Header']['table_id'].split()[-1]\n",
    "        \n",
    "        mip_tables_data[table_name] = table_data['variable_entry']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd55e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frequency': 'mon',\n",
       " 'modeling_realm': 'atmos',\n",
       " 'standard_name': 'air_temperature',\n",
       " 'units': 'K',\n",
       " 'cell_methods': 'area: time: mean',\n",
       " 'cell_measures': 'area: areacella',\n",
       " 'long_name': 'Near-Surface Air Temperature',\n",
       " 'comment': 'near-surface (usually, 2 meter) air temperature',\n",
       " 'dimensions': 'longitude latitude time height2m',\n",
       " 'out_name': 'tas',\n",
       " 'type': 'real',\n",
       " 'positive': '',\n",
       " 'valid_min': '',\n",
       " 'valid_max': '',\n",
       " 'ok_min_mean_abs': '',\n",
       " 'ok_max_mean_abs': ''}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mip_tables_data['Amon']['tas']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc735b59",
   "metadata": {},
   "source": [
    "Integrate data from the CMIP6 data request. Add unique identifiers for provenance information and insert QC ranges held in the data request, but not propagated to the mip tables previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cf7764f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: version difference between /home/h03/hadmm/CDDS/dreq/dreq_versions/01.00.33/dreqPy/docs/dreq.xml [01.00.33] and /home/h03/hadmm/CDDS/dreq/dreq_versions/01.00.33/dreqPy/docs/dreqSupp.xml [01.00.32]\n"
     ]
    }
   ],
   "source": [
    "# get dictionary of uids corresponding to CMOR variables from data request\n",
    "dq = dreq.loadDreq()\n",
    "dreq_uids = {(i.mipTable, i.label): i.uid for i in dq.inx.CMORvar.uid.values()}\n",
    "QC_FIELDS = ['valid_min', 'valid_max', 'ok_min_mean_abs', 'ok_max_mean_abs']\n",
    "\n",
    "# loop over tables\n",
    "for table in mip_tables_data:\n",
    "    for variable in mip_tables_data[table]:\n",
    "        # add data request uid to mip tables, to be used in provenance data later.\n",
    "        uid = dreq_uids[(table, variable)]\n",
    "        mip_tables_data[table][variable]['dreq_uid'] = uid\n",
    "        \n",
    "        # add QC information held in data request if available\n",
    "        qc_key = '{}-{}'.format(table, variable)\n",
    "        if qc_key in dq.inx.qcranges.label:\n",
    "            \n",
    "            qc_info_uid = dq.inx.qcranges.label[qc_key]\n",
    "            qc_info_obj = dq.inx.uid[qc_info_uid[0]]\n",
    "            qc_info = {}\n",
    "            for field in QC_FIELDS:\n",
    "                value = getattr(qc_info_obj, field)\n",
    "                # Some qc entries have another object as one of their fields.\n",
    "                # Filter these out as we can't handle this.\n",
    "                if isinstance(value, (int, float)):\n",
    "                    qc_info[field] = value\n",
    "            # Update MIP table QC information        \n",
    "            mip_tables_data[table][variable].update(qc_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd486b92",
   "metadata": {},
   "source": [
    "MIP table entries now look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f629d2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frequency': 'mon',\n",
       " 'modeling_realm': 'atmos',\n",
       " 'standard_name': 'air_temperature',\n",
       " 'units': 'K',\n",
       " 'cell_methods': 'area: time: mean',\n",
       " 'cell_measures': 'area: areacella',\n",
       " 'long_name': 'Near-Surface Air Temperature',\n",
       " 'comment': 'near-surface (usually, 2 meter) air temperature',\n",
       " 'dimensions': 'longitude latitude time height2m',\n",
       " 'out_name': 'tas',\n",
       " 'type': 'real',\n",
       " 'positive': '',\n",
       " 'valid_min': 170.0,\n",
       " 'valid_max': 350.0,\n",
       " 'ok_min_mean_abs': 255.0,\n",
       " 'ok_max_mean_abs': 295.0,\n",
       " 'dreq_uid': 'bab9237c-e5dd-11e5-8482-ac72891c3257'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mip_tables_data['Amon']['tas']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27be381",
   "metadata": {},
   "source": [
    "Assign default MIP table prefix based on realm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "648756a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "realms = {\n",
    "    \"aerosol\": \"AE\", \n",
    "    \"atmos\": \"AP\", \n",
    "    \"atmosChem\": \"AC\", \n",
    "    \"land\": \"LP\", \n",
    "    \"landIce\": \"LI\", \n",
    "    \"ocean\":\"OP\", \n",
    "    \"ocnBgchem\": \"OB\", \n",
    "    \"seaIce\": \"SI\", \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439712b9",
   "metadata": {},
   "source": [
    "Reassign variables to new MIP tables. For clarity I've replaced 1hrCM with monDiurnal -- this affects variables in the E1hrClimMon table which are reported as monthly means sampled at each hour of the day, e.g. average of values sampled at 00Z, 01Z, ... 22Z, 23Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c775f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tables = defaultdict(lambda: defaultdict(list))\n",
    "new_table_frequency = {}\n",
    "for mip_table_name, data in mip_tables_data.items():\n",
    "    \n",
    "    for var_name, entry in data.items():\n",
    "        dimensions = entry['dimensions'].split()\n",
    "        prefix = realms[entry['modeling_realm'].split()[0]]\n",
    "        frequency = entry['frequency']\n",
    "        cell_methods = entry['cell_methods']\n",
    "        \n",
    "        # replace monC (monthly climatology) with monClim for clarity\n",
    "        if frequency == 'monC':\n",
    "            frequency = 'monClim'\n",
    "        # replace 1hrCM (monthly mean sampled at defined time of day) with monDiurnal \n",
    "        elif frequency == '1hrCM':\n",
    "            frequency = 'monDiurnal'\n",
    "        \n",
    "        # Construct suffixes\n",
    "        suffix = ''\n",
    "        \n",
    "        if 'site' in dimensions:\n",
    "            # Site specific (CFsites)\n",
    "            suffix = 'Site'\n",
    "        elif mip_table_name in ['IyrAnt', 'IfxAnt', 'ImonAnt']:\n",
    "            # Glacier-Ice-Antarctica    \n",
    "            prefix = 'GIA'\n",
    "        elif mip_table_name in ['IyrGre', 'IfxGre', 'ImonGre']:\n",
    "            # Glacier-Ice-Greenland    \n",
    "            prefix = 'GIG' \n",
    "        elif frequency == 'fx':\n",
    "            # Don't separate fixed fields\n",
    "            pass\n",
    "        elif 'longitude' not in dimensions and 'latitude' in dimensions:\n",
    "            # zonal means\n",
    "            suffix = 'Z'\n",
    "        elif any([i in dimensions for i in ['alevel', 'alevhalf', 'olevel', 'olevhalf']]) and frequency != 'fx':\n",
    "            # atmosphere & ocean levels\n",
    "            suffix = 'Lev'\n",
    "        \n",
    "        new_table = '{}{}{}'.format(prefix, frequency, suffix)\n",
    "\n",
    "        new_tables[new_table][var_name].append((mip_table_name, var_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20625e0b",
   "metadata": {},
   "source": [
    "List new tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d96e6eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78,\n",
       " ['ACmon',\n",
       "  'ACmonZ',\n",
       "  'AE1hr',\n",
       "  'AE3hrPt',\n",
       "  'AE3hrPtLev',\n",
       "  'AE6hr',\n",
       "  'AE6hrPt',\n",
       "  'AE6hrPtLev',\n",
       "  'AEday',\n",
       "  'AEmon',\n",
       "  'AEmonLev',\n",
       "  'AEmonZ',\n",
       "  'AEsubhrPt',\n",
       "  'AEsubhrPtSite',\n",
       "  'AP1hr',\n",
       "  'AP1hrPt',\n",
       "  'AP3hr',\n",
       "  'AP3hrPt',\n",
       "  'AP3hrPtLev',\n",
       "  'AP6hr',\n",
       "  'AP6hrPt',\n",
       "  'AP6hrPtLev',\n",
       "  'AP6hrPtZ',\n",
       "  'APday',\n",
       "  'APdayLev',\n",
       "  'APdayZ',\n",
       "  'APfx',\n",
       "  'APfxSite',\n",
       "  'APmon',\n",
       "  'APmonClim',\n",
       "  'APmonClimLev',\n",
       "  'APmonDiurnal',\n",
       "  'APmonLev',\n",
       "  'APmonZ',\n",
       "  'APsubhrPt',\n",
       "  'APsubhrPtLev',\n",
       "  'APsubhrPtSite',\n",
       "  'GIAfx',\n",
       "  'GIAmon',\n",
       "  'GIAyr',\n",
       "  'GIGfx',\n",
       "  'GIGmon',\n",
       "  'GIGyr',\n",
       "  'LI3hrPt',\n",
       "  'LI6hrPt',\n",
       "  'LIday',\n",
       "  'LIfx',\n",
       "  'LImon',\n",
       "  'LIsubhrPtSite',\n",
       "  'LP3hr',\n",
       "  'LP3hrPt',\n",
       "  'LP6hrPt',\n",
       "  'LPday',\n",
       "  'LPfx',\n",
       "  'LPmon',\n",
       "  'LPyr',\n",
       "  'LPyrPt',\n",
       "  'OBday',\n",
       "  'OBmon',\n",
       "  'OBmonLev',\n",
       "  'OByr',\n",
       "  'OByrLev',\n",
       "  'OP3hrPt',\n",
       "  'OPday',\n",
       "  'OPdec',\n",
       "  'OPdecLev',\n",
       "  'OPdecZ',\n",
       "  'OPfx',\n",
       "  'OPmon',\n",
       "  'OPmonClim',\n",
       "  'OPmonClimLev',\n",
       "  'OPmonLev',\n",
       "  'OPmonZ',\n",
       "  'OPyr',\n",
       "  'OPyrLev',\n",
       "  'SIday',\n",
       "  'SImon',\n",
       "  'SImonPt'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_tables), sorted(list(new_tables.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf0238",
   "metadata": {},
   "source": [
    "Example of variables in a particular table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84a459bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'hfls': [('Esubhr', 'hfls')],\n",
       "             'hfss': [('Esubhr', 'hfss')],\n",
       "             'huss': [('Esubhr', 'huss')],\n",
       "             'pr': [('Esubhr', 'pr')],\n",
       "             'prc': [('Esubhr', 'prc')],\n",
       "             'prw': [('Esubhr', 'prw')],\n",
       "             'ps': [('Esubhr', 'ps')],\n",
       "             'rlut': [('Esubhr', 'rlut')],\n",
       "             'rsdt': [('Esubhr', 'rsdt')],\n",
       "             'rsut': [('Esubhr', 'rsut')],\n",
       "             'tas': [('Esubhr', 'tas')]})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tables['APsubhrPt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18082445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'ocontempdiff': [('Emon', 'ocontempdiff')],\n",
       "             'ocontemppadvect': [('Emon', 'ocontemppadvect')],\n",
       "             'ocontemppmdiff': [('Emon', 'ocontemppmdiff')],\n",
       "             'ocontemppsmadvect': [('Emon', 'ocontemppsmadvect')],\n",
       "             'ocontemprmadvect': [('Emon', 'ocontemprmadvect')],\n",
       "             'ocontemptend': [('Emon', 'ocontemptend')],\n",
       "             'opottempdiff': [('Emon', 'opottempdiff')],\n",
       "             'opottemppadvect': [('Emon', 'opottemppadvect')],\n",
       "             'opottemppmdiff': [('Emon', 'opottemppmdiff')],\n",
       "             'opottemppsmadvect': [('Emon', 'opottemppsmadvect')],\n",
       "             'opottemprmadvect': [('Emon', 'opottemprmadvect')],\n",
       "             'opottemptend': [('Emon', 'opottemptend')],\n",
       "             'osaltdiff': [('Emon', 'osaltdiff')],\n",
       "             'osaltpadvect': [('Emon', 'osaltpadvect')],\n",
       "             'osaltpmdiff': [('Emon', 'osaltpmdiff')],\n",
       "             'osaltpsmadvect': [('Emon', 'osaltpsmadvect')],\n",
       "             'osaltrmadvect': [('Emon', 'osaltrmadvect')],\n",
       "             'osalttend': [('Emon', 'osalttend')],\n",
       "             'pabigthetao': [('Emon', 'pabigthetao')],\n",
       "             'pathetao': [('Emon', 'pathetao')],\n",
       "             'prbigthetao': [('Emon', 'prbigthetao')],\n",
       "             'prthetao': [('Emon', 'prthetao')],\n",
       "             'prw18O': [('Emon', 'prw18O')],\n",
       "             'rsdoabsorb': [('Emon', 'rsdoabsorb')],\n",
       "             'sw17O': [('Emon', 'sw17O')],\n",
       "             'sw18O': [('Emon', 'sw18O')],\n",
       "             'sw2H': [('Emon', 'sw2H')],\n",
       "             'agessc': [('Omon', 'agessc')],\n",
       "             'bigthetao': [('Omon', 'bigthetao')],\n",
       "             'cfc11': [('Omon', 'cfc11')],\n",
       "             'cfc12': [('Omon', 'cfc12')],\n",
       "             'ficeberg': [('Omon', 'ficeberg')],\n",
       "             'hfibthermds': [('Omon', 'hfibthermds')],\n",
       "             'hfrunoffds': [('Omon', 'hfrunoffds')],\n",
       "             'hfsifrazil': [('Omon', 'hfsifrazil')],\n",
       "             'hfsnthermds': [('Omon', 'hfsnthermds')],\n",
       "             'masscello': [('Omon', 'masscello')],\n",
       "             'msftyz': [('Omon', 'msftyz')],\n",
       "             'msftyzmpa': [('Omon', 'msftyzmpa')],\n",
       "             'obvfsq': [('Omon', 'obvfsq')],\n",
       "             'rsdo': [('Omon', 'rsdo')],\n",
       "             'sf6': [('Omon', 'sf6')],\n",
       "             'so': [('Omon', 'so')],\n",
       "             'thetao': [('Omon', 'thetao')],\n",
       "             'thkcello': [('Omon', 'thkcello')],\n",
       "             'umo': [('Omon', 'umo')],\n",
       "             'uo': [('Omon', 'uo')],\n",
       "             'vmo': [('Omon', 'vmo')],\n",
       "             'vo': [('Omon', 'vo')],\n",
       "             'volcello': [('Omon', 'volcello')],\n",
       "             'wmo': [('Omon', 'wmo')],\n",
       "             'wo': [('Omon', 'wo')],\n",
       "             'zfullo': [('Omon', 'zfullo')],\n",
       "             'zhalfo': [('Omon', 'zhalfo')]})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tables['OPmonLev']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5026f92",
   "metadata": {},
   "source": [
    "Fixed tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e375b142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'APfxSite': defaultdict(list,\n",
       "             {'latitude': [('CFsubhr', 'latitude')],\n",
       "              'longitude': [('CFsubhr', 'longitude')]}),\n",
       " 'LPfx': defaultdict(list,\n",
       "             {'clayfrac': [('Efx', 'clayfrac')],\n",
       "              'fldcapacity': [('Efx', 'fldcapacity')],\n",
       "              'ksat': [('Efx', 'ksat')],\n",
       "              'rootdsl': [('Efx', 'rootdsl')],\n",
       "              'sandfrac': [('Efx', 'sandfrac')],\n",
       "              'slthick': [('Efx', 'slthick')],\n",
       "              'vegHeight': [('Efx', 'vegHeight')],\n",
       "              'wilt': [('Efx', 'wilt')],\n",
       "              'areacellr': [('fx', 'areacellr')],\n",
       "              'mrsofc': [('fx', 'mrsofc')],\n",
       "              'orog': [('fx', 'orog')],\n",
       "              'rootd': [('fx', 'rootd')],\n",
       "              'sftgif': [('fx', 'sftgif')]}),\n",
       " 'APfx': defaultdict(list,\n",
       "             {'ps': [('Efx', 'ps')],\n",
       "              'rld': [('Efx', 'rld')],\n",
       "              'rlu': [('Efx', 'rlu')],\n",
       "              'rsd': [('Efx', 'rsd')],\n",
       "              'rsu': [('Efx', 'rsu')],\n",
       "              'siltfrac': [('Efx', 'siltfrac')],\n",
       "              'areacella': [('fx', 'areacella')],\n",
       "              'sftlf': [('fx', 'sftlf')],\n",
       "              'zfull': [('fx', 'zfull')]}),\n",
       " 'LIfx': defaultdict(list,\n",
       "             {'sftflf': [('Efx', 'sftflf')], 'sftgrf': [('Efx', 'sftgrf')]}),\n",
       " 'GIAfx': defaultdict(list,\n",
       "             {'areacellg': [('IfxAnt', 'areacellg')],\n",
       "              'hfgeoubed': [('IfxAnt', 'hfgeoubed')],\n",
       "              'lithk': [('IfxAnt', 'lithk')],\n",
       "              'topg': [('IfxAnt', 'topg')]}),\n",
       " 'GIGfx': defaultdict(list,\n",
       "             {'areacellg': [('IfxGre', 'areacellg')],\n",
       "              'hfgeoubed': [('IfxGre', 'hfgeoubed')],\n",
       "              'lithk': [('IfxGre', 'lithk')],\n",
       "              'topg': [('IfxGre', 'topg')]}),\n",
       " 'OPfx': defaultdict(list,\n",
       "             {'areacello': [('Ofx', 'areacello')],\n",
       "              'basin': [('Ofx', 'basin')],\n",
       "              'deptho': [('Ofx', 'deptho')],\n",
       "              'hfgeou': [('Ofx', 'hfgeou')],\n",
       "              'masscello': [('Ofx', 'masscello')],\n",
       "              'sftof': [('Ofx', 'sftof')],\n",
       "              'thkcello': [('Ofx', 'thkcello')],\n",
       "              'ugrido': [('Ofx', 'ugrido')],\n",
       "              'volcello': [('Ofx', 'volcello')]})}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i:j for i,j in new_tables.items() if 'fx' in i}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea16c242",
   "metadata": {},
   "source": [
    "The fixed variables could do with some re-arrangement, e.g. siltfrac should be in LPfx, APfxSite should be removed. Leave this for after first draft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20d70ec",
   "metadata": {},
   "source": [
    "## Branded variable assignment\n",
    "\n",
    "Add branded variable name as a variable attribute, but this methodology likely needs updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be538126",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERVAL_LOOKUP = {\n",
    "    'subhrPt': 'subhr',\n",
    "    '1hr': '1hr', \n",
    "    '1hrCM': '1hrCM', \n",
    "    '1hrPt': '1hr',\n",
    "    '3hr': '3hr', \n",
    "    '3hrPt': '3hr',\n",
    "    '6hr': '6hr', \n",
    "    '6hrPt': '6hr',\n",
    "    'day': 'day',\n",
    "    'mon': 'mon', \n",
    "    'monC': 'mon', \n",
    "    'monPt': 'mon',\n",
    "    'yr': 'yr', \n",
    "    'yrPt': 'yr',\n",
    "    'dec':'dec',\n",
    "    'fx': 'fx',\n",
    "}\n",
    "\n",
    "\n",
    "def interval_label(variable):\n",
    "    return INTERVAL_LOOKUP[variable['frequency']]\n",
    "\n",
    "\n",
    "REALM_LOOKUP = {\n",
    "    'atmos': 'ap',\n",
    "    'atmosChem': 'ac',\n",
    "    'aerosol': 'ae',\n",
    "    'land': 'ld',\n",
    "    'landIce': 'li',\n",
    "    'ocean': 'op',\n",
    "    'ocnBgchem': 'oc',\n",
    "    'seaIce': 'si',\n",
    "}\n",
    "\n",
    "\n",
    "def realm_label(variable):\n",
    "    # not taking into account secondary realms, will have errors\n",
    "    return REALM_LOOKUP[variable['modeling_realm'].split(' ')[0]]\n",
    "\n",
    "\n",
    "TIME_LOOKUP = {\n",
    "    'time': 'tav',\n",
    "    'time1': 'tpt',\n",
    "    'time2': 'tcla',\n",
    "    'time3': 'tcld',\n",
    "}\n",
    "\n",
    "\n",
    "def temporal_label(variable):\n",
    "    # default of \"none\" to cover fixed field case\n",
    "    label = 'none'\n",
    "    for dim in variable['dimensions'].split(' '):\n",
    "        if dim in TIME_LOOKUP:\n",
    "            label = TIME_LOOKUP[dim]\n",
    "            break\n",
    "    return label\n",
    "\n",
    "VERTICAL_LOOKUP = {\n",
    "    'sdepth': 'l',\n",
    "    'olevel': 'l',\n",
    "    'alevel': 'l',\n",
    "    'alevhalf': 'l',\n",
    "    'olevhalf': 'l',\n",
    "    'rho': 'rhon',\n",
    "    'height2m': 'h02',\n",
    "    'height10m': 'h010',\n",
    "    'height100m': 'h0100',\n",
    "    'sdepth1': 'z01s',\n",
    "    'sdepth10': 'z010',\n",
    "    'depth0m': 'z00',\n",
    "    'depth100m': 'z0100',\n",
    "    'depth300m': 'z0300',\n",
    "    'depth700m': 'z0700',\n",
    "    'depth2000m': 'z02000',\n",
    "    'olayer100m': 'z0100',\n",
    "    'p10': 'p010',\n",
    "    'p100': 'p0100',\n",
    "    'p220': 'p0220',\n",
    "    'p500': 'p0500',\n",
    "    'p560': 'p0560',\n",
    "    'pl700': 'p0700',\n",
    "    'p840': 'p0840',\n",
    "    'p850': 'p0850',\n",
    "    'p1000': 'p01000',\n",
    "    'alt16': 'z16',\n",
    "    'alt40': 'z40',\n",
    "    'plev3': 'p3',\n",
    "    'plev4': 'p4',\n",
    "    'plev8': 'p8',\n",
    "    'plev7c': 'p7c',\n",
    "    'plev7h': 'p7h',\n",
    "    'plev19': 'p19',\n",
    "    'plev27': 'p27',\n",
    "    'plev39': 'p39',\n",
    "}\n",
    "\n",
    "def vertical_label(variable):\n",
    "    for dim in variable['dimensions'].split(' '):\n",
    "        if dim in VERTICAL_LOOKUP:\n",
    "            return VERTICAL_LOOKUP[dim]\n",
    "    # default:\n",
    "    return 'z0'\n",
    "        \n",
    "\n",
    "def horizontal_label(variable):\n",
    "    dimensions = set(variable['dimensions'].split(' '))\n",
    "    latlon = {'latitude', 'longitude'}\n",
    "    ant = {'xant', 'yant'}\n",
    "    gre = {'xgre', 'ygre'}\n",
    "    latbas = {'latitude', 'basin'}\n",
    "    \n",
    "    if (latlon.intersection(dimensions) == latlon or\n",
    "        ant.intersection(dimensions) == ant or\n",
    "        gre.intersection(dimensions) == gre):\n",
    "        # simple lat lon\n",
    "        result = 'hxy'\n",
    "    elif ('latitude' in dimensions and \n",
    "        'longitude' not in dimensions and \n",
    "        'basin' not in dimensions):\n",
    "        # zonal means, but not by basin\n",
    "        result = 'hy'\n",
    "    elif not {'latitude', 'yant', 'ygre', 'gridLatitude', 'site', 'oline', 'oline'}.intersection(dimensions):\n",
    "        # spatial means means\n",
    "        result = 'hm'\n",
    "    elif latbas.intersection(dimensions) == latbas:\n",
    "        # basin means\n",
    "        result = 'hys'\n",
    "    elif 'site' in dimensions:\n",
    "        # CF sites\n",
    "        result = 'hxys'\n",
    "    elif 'oline' in dimensions or 'siline' in dimensions:\n",
    "        # transports\n",
    "        result = 'ht'\n",
    "    else:\n",
    "        raise KeyError('Could not determine label for \"{}\"'.format(variable['dimensions']))\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def branded_variable_name(variable):\n",
    "    # Order of terms after variable label\n",
    "    functions = [interval_label, realm_label, temporal_label, vertical_label, horizontal_label]\n",
    "    return '{}_{}'.format(variable['out_name'], '-'.join([f(variable) for f in functions]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f0d164",
   "metadata": {},
   "source": [
    "Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1859bffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hus_mon-ap-tav-p27-hxy', 'hus_mon-ap-tav-p7h-hxy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branded_variable_name(mip_tables_data['Emon']['hus27']), branded_variable_name(mip_tables_data['Emon']['hus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25ad1dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rlut_1hrCM-ap-tcld-z0-hxy'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branded_variable_name(mip_tables_data['E1hrClimMon']['rlut'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc247f27",
   "metadata": {},
   "source": [
    "Put together a list of branded variable names and add the branded variable name to the MIP table entry.\n",
    "There are a lot of \"collisions\", i.e. multiple variables with the same branded variable name, most of which relate to the icesheet variables over Greenland and Antarctica. For now add suffix \"A\" or \"G\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab15f5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps_3hr-ap-tpt-z0-hxy [('3hr', 'ps'), ('CF3hr', 'ps'), ('E3hrPt', 'ps')]\n",
      "ps_mon-ap-tav-z0-hxy [('AERmon', 'ps'), ('Amon', 'ps'), ('CFmon', 'ps'), ('Emon', 'ps')]\n",
      "prsn_mon-ap-tav-z0-hxy [('Amon', 'prsn'), ('Omon', 'prsn')]\n",
      "sbl_mon-li-tav-z0-hxy [('Amon', 'sbl'), ('LImon', 'sbl')]\n",
      "clt_day-ap-tav-z0-hxy [('Eday', 'clt'), ('day', 'clt')]\n",
      "hfls_day-ap-tav-z0-hxy [('Eday', 'hfls'), ('day', 'hfls')]\n",
      "hfss_day-ap-tav-z0-hxy [('Eday', 'hfss'), ('day', 'hfss')]\n",
      "rls_day-ap-tav-z0-hxy [('Eday', 'rls'), ('day', 'rls')]\n",
      "rss_day-ap-tav-z0-hxy [('Eday', 'rss'), ('day', 'rss')]\n"
     ]
    }
   ],
   "source": [
    "branded_vns = defaultdict(list)\n",
    "\n",
    "for table in mip_tables_data:\n",
    "    for variable, entry in mip_tables_data[table].items():\n",
    "        bvn = branded_variable_name(entry)\n",
    "        # allow for the Glacier ice to be distinguished by appending 'G' for greenland and 'A' for antarctica\n",
    "        if 'Gre' in table:\n",
    "            bvn += 'G'\n",
    "        if 'Ant' in table:\n",
    "            bvn += 'A'\n",
    "        entry['branded_variable_name'] = bvn\n",
    "        branded_vns[bvn].append((table, variable))\n",
    "\n",
    "for bvn in branded_vns:\n",
    "    if len(branded_vns[bvn]) != 1:\n",
    "        print(bvn, branded_vns[bvn])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a28854",
   "metadata": {},
   "source": [
    "Some of the above are dealt with later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8074ed",
   "metadata": {},
   "source": [
    "## Check for conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ecba3",
   "metadata": {},
   "source": [
    "Build lists of new MIP table, variable and where the variable came from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "267cf5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table_mapping = defaultdict(lambda: defaultdict(list))\n",
    "new_table_mapping_with_conflicts = defaultdict(lambda: defaultdict(list))\n",
    "for table in new_tables:\n",
    "    for variable in new_tables[table]:\n",
    "        new_table_mapping[table][variable]+= new_tables[table][variable]\n",
    "        if len(new_tables[table][variable]) > 1:\n",
    "            new_table_mapping_with_conflicts[table][variable] += new_tables[table][variable]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906fc6fc",
   "metadata": {},
   "source": [
    "Sample of the entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac8d08e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'hus': [('6hrLev', 'hus')],\n",
       "             'pfull': [('6hrLev', 'pfull')],\n",
       "             'ta': [('6hrLev', 'ta')],\n",
       "             'ua': [('6hrLev', 'ua')],\n",
       "             'va': [('6hrLev', 'va')]})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_table_mapping['AP6hrPtLev']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718622db",
   "metadata": {},
   "source": [
    "List variables with table conflicts, i.e. where a new variable has multiple corresponding original variables, and report whether/how the variables differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2a282a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'AP3hrPt': defaultdict(list,\n",
       "                         {'ps': [('3hr', 'ps'),\n",
       "                           ('CF3hr', 'ps'),\n",
       "                           ('E3hrPt', 'ps')]}),\n",
       "             'APday': defaultdict(list,\n",
       "                         {'clt': [('Eday', 'clt'), ('day', 'clt')],\n",
       "                          'hfls': [('Eday', 'hfls'), ('day', 'hfls')],\n",
       "                          'hfss': [('Eday', 'hfss'), ('day', 'hfss')],\n",
       "                          'hus': [('Eday', 'hus'), ('day', 'hus')],\n",
       "                          'rls': [('Eday', 'rls'), ('day', 'rls')],\n",
       "                          'rss': [('Eday', 'rss'), ('day', 'rss')],\n",
       "                          'ta': [('Eday', 'ta'), ('day', 'ta')],\n",
       "                          'ua': [('Eday', 'ua'), ('day', 'ua')],\n",
       "                          'va': [('Eday', 'va'), ('day', 'va')],\n",
       "                          'wap': [('Eday', 'wap'), ('day', 'wap')],\n",
       "                          'zg': [('Eday', 'zg'), ('day', 'zg')]}),\n",
       "             'APmon': defaultdict(list,\n",
       "                         {'ps': [('AERmon', 'ps'),\n",
       "                           ('Amon', 'ps'),\n",
       "                           ('CFmon', 'ps'),\n",
       "                           ('Emon', 'ps')],\n",
       "                          'hus': [('Amon', 'hus'), ('Emon', 'hus')],\n",
       "                          'prsn': [('Amon', 'prsn'), ('Omon', 'prsn')],\n",
       "                          'ua': [('Amon', 'ua'), ('Emon', 'ua')],\n",
       "                          'va': [('Amon', 'va'), ('Emon', 'va')]}),\n",
       "             'LImon': defaultdict(list,\n",
       "                         {'sbl': [('Amon', 'sbl'), ('LImon', 'sbl')]})})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_table_mapping_with_conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dcab03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP3hrPt/ps\n",
      "\t3hr/ps, CF3hr/ps: no differences\n",
      "\t3hr/ps, E3hrPt/ps: no differences\n",
      "APday/clt\n",
      "\tcell_methods\n",
      "\t\tEday/clt cell_methods=area: mean where land time: mean\n",
      "\t\tday/clt cell_methods=area: time: mean\n",
      "APday/hfls\n",
      "\tcell_methods\n",
      "\t\tEday/hfls cell_methods=area: mean where land time: mean\n",
      "\t\tday/hfls cell_methods=area: time: mean\n",
      "APday/hfss\n",
      "\tcell_methods\n",
      "\t\tEday/hfss cell_methods=area: mean where land time: mean\n",
      "\t\tday/hfss cell_methods=area: time: mean\n",
      "APday/hus\n",
      "\tdimensions\n",
      "\t\tEday/hus dimensions=longitude latitude plev19 time\n",
      "\t\tday/hus dimensions=longitude latitude plev8 time\n",
      "\tbranded_variable_name\n",
      "\t\tEday/hus branded_variable_name=hus_day-ap-tav-p19-hxy\n",
      "\t\tday/hus branded_variable_name=hus_day-ap-tav-p8-hxy\n",
      "APday/rls\n",
      "\tcell_methods\n",
      "\t\tEday/rls cell_methods=area: mean where land time: mean\n",
      "\t\tday/rls cell_methods=area: time: mean\n",
      "APday/rss\n",
      "\tcell_methods\n",
      "\t\tEday/rss cell_methods=area: mean where land time: mean\n",
      "\t\tday/rss cell_methods=area: time: mean\n",
      "APday/ta\n",
      "\tdimensions\n",
      "\t\tEday/ta dimensions=longitude latitude plev19 time\n",
      "\t\tday/ta dimensions=longitude latitude plev8 time\n",
      "\tbranded_variable_name\n",
      "\t\tEday/ta branded_variable_name=ta_day-ap-tav-p19-hxy\n",
      "\t\tday/ta branded_variable_name=ta_day-ap-tav-p8-hxy\n",
      "APday/ua\n",
      "\tdimensions\n",
      "\t\tEday/ua dimensions=longitude latitude plev19 time\n",
      "\t\tday/ua dimensions=longitude latitude plev8 time\n",
      "\tbranded_variable_name\n",
      "\t\tEday/ua branded_variable_name=ua_day-ap-tav-p19-hxy\n",
      "\t\tday/ua branded_variable_name=ua_day-ap-tav-p8-hxy\n",
      "APday/va\n",
      "\tdimensions\n",
      "\t\tEday/va dimensions=longitude latitude plev19 time\n",
      "\t\tday/va dimensions=longitude latitude plev8 time\n",
      "\tbranded_variable_name\n",
      "\t\tEday/va branded_variable_name=va_day-ap-tav-p19-hxy\n",
      "\t\tday/va branded_variable_name=va_day-ap-tav-p8-hxy\n",
      "APday/wap\n",
      "\tdimensions\n",
      "\t\tEday/wap dimensions=longitude latitude plev19 time\n",
      "\t\tday/wap dimensions=longitude latitude plev8 time\n",
      "\tbranded_variable_name\n",
      "\t\tEday/wap branded_variable_name=wap_day-ap-tav-p19-hxy\n",
      "\t\tday/wap branded_variable_name=wap_day-ap-tav-p8-hxy\n",
      "APday/zg\n",
      "\tdimensions\n",
      "\t\tEday/zg dimensions=longitude latitude plev19 time\n",
      "\t\tday/zg dimensions=longitude latitude plev8 time\n",
      "\tbranded_variable_name\n",
      "\t\tEday/zg branded_variable_name=zg_day-ap-tav-p19-hxy\n",
      "\t\tday/zg branded_variable_name=zg_day-ap-tav-p8-hxy\n",
      "APmon/ps\n",
      "\tAERmon/ps, Amon/ps: no differences\n",
      "\tAERmon/ps, CFmon/ps: no differences\n",
      "\tAERmon/ps, Emon/ps: no differences\n",
      "APmon/hus\n",
      "\tcell_methods\n",
      "\t\tAmon/hus cell_methods=time: mean\n",
      "\t\tEmon/hus cell_methods=area: time: mean\n",
      "\tdimensions\n",
      "\t\tAmon/hus dimensions=longitude latitude plev19 time\n",
      "\t\tEmon/hus dimensions=longitude latitude plev7h time\n",
      "\tbranded_variable_name\n",
      "\t\tAmon/hus branded_variable_name=hus_mon-ap-tav-p19-hxy\n",
      "\t\tEmon/hus branded_variable_name=hus_mon-ap-tav-p7h-hxy\n",
      "APmon/prsn\n",
      "\tcell_methods\n",
      "\t\tAmon/prsn cell_methods=area: time: mean\n",
      "\t\tOmon/prsn cell_methods=area: mean where ice_free_sea over sea time: mean\n",
      "\tcell_measures\n",
      "\t\tAmon/prsn cell_measures=area: areacella\n",
      "\t\tOmon/prsn cell_measures=area: areacello\n",
      "\tlong_name\n",
      "\t\tAmon/prsn long_name=Snowfall Flux\n",
      "\t\tOmon/prsn long_name=Snowfall Flux where Ice Free Ocean over Sea\n",
      "APmon/ua\n",
      "\tcell_methods\n",
      "\t\tAmon/ua cell_methods=time: mean\n",
      "\t\tEmon/ua cell_methods=area: time: mean\n",
      "\tdimensions\n",
      "\t\tAmon/ua dimensions=longitude latitude plev19 time\n",
      "\t\tEmon/ua dimensions=longitude latitude plev7h time\n",
      "\tbranded_variable_name\n",
      "\t\tAmon/ua branded_variable_name=ua_mon-ap-tav-p19-hxy\n",
      "\t\tEmon/ua branded_variable_name=ua_mon-ap-tav-p7h-hxy\n",
      "APmon/va\n",
      "\tcell_methods\n",
      "\t\tAmon/va cell_methods=time: mean\n",
      "\t\tEmon/va cell_methods=area: time: mean\n",
      "\tdimensions\n",
      "\t\tAmon/va dimensions=longitude latitude plev19 time\n",
      "\t\tEmon/va dimensions=longitude latitude plev7h time\n",
      "\tbranded_variable_name\n",
      "\t\tAmon/va branded_variable_name=va_mon-ap-tav-p19-hxy\n",
      "\t\tEmon/va branded_variable_name=va_mon-ap-tav-p7h-hxy\n",
      "LImon/sbl\n",
      "\tcell_methods\n",
      "\t\tAmon/sbl cell_methods=area: time: mean\n",
      "\t\tLImon/sbl cell_methods=area: mean where land time: mean\n"
     ]
    }
   ],
   "source": [
    "for table, variables in new_table_mapping_with_conflicts.items():\n",
    "    \n",
    "    for variable, mappings in variables.items():\n",
    "        print('{}/{}'.format(table, variable))\n",
    "        ref_mapping = mappings[0]\n",
    "        ref_entry = mip_tables_data[ref_mapping[0]][ref_mapping[1]]\n",
    "        differences = False\n",
    "        for mapping in mappings[1:]:\n",
    "            test_entry = mip_tables_data[mapping[0]][mapping[1]]\n",
    "            for field in ref_entry:\n",
    "                if field == 'dreq_uid' or field in QC_FIELDS:\n",
    "                    # Don't report data request identifier differences or qc information\n",
    "                    continue\n",
    "                if ref_entry[field] != test_entry[field]:\n",
    "                    differences = True\n",
    "                    print('\\t{}'.format(field))\n",
    "                    print('\\t\\t{}/{} {}={}'.format(ref_mapping[0], ref_mapping[1], field, ref_entry[field]))\n",
    "                    print('\\t\\t{}/{} {}={}'.format(mapping[0], mapping[1], field, test_entry[field]))\n",
    "            if not differences:\n",
    "                print('\\t{}/{}, {}/{}: no differences'.format(ref_mapping[0], ref_mapping[1], mapping[0], mapping[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69d9a58",
   "metadata": {},
   "source": [
    "### Manual changes required:\n",
    "\n",
    "Merge entries:\n",
    "\n",
    "* AP3hrPt ps ['3hr', 'CF3hr', 'E3hrPt']\n",
    "* APmon ps ['AERmon', 'Amon', 'CFmon', 'Emon']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc7d2a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3hr', 'ps'), ('CF3hr', 'ps'), ('E3hrPt', 'ps')]\n",
      "[('3hr', 'ps')]\n",
      "[('AERmon', 'ps'), ('Amon', 'ps'), ('CFmon', 'ps'), ('Emon', 'ps')]\n",
      "[('Amon', 'ps')]\n"
     ]
    }
   ],
   "source": [
    "print(new_table_mapping['AP3hrPt']['ps']) \n",
    "new_table_mapping['AP3hrPt']['ps'] = new_table_mapping['AP3hrPt']['ps'][:1]\n",
    "print(new_table_mapping['AP3hrPt']['ps']) \n",
    "print(new_table_mapping['APmon']['ps']) \n",
    "new_table_mapping['APmon']['ps'] = new_table_mapping['APmon']['ps'][1:2] # choose Amon\n",
    "print(new_table_mapping['APmon']['ps'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a5447f",
   "metadata": {},
   "source": [
    "Retain entry with cell_methods \"area: time: mean\" (MIP table \"day\"). Entries marked with \"area: mean where land time: mean\" should be reconstructable using land sea mask.\n",
    "* APday clt ['Eday', 'day']\n",
    "* APday hfls ['Eday', 'day']\n",
    "* APday hfss ['Eday', 'day']\n",
    "* APday rls ['Eday', 'day']\n",
    "* APday rss ['Eday', 'day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e89d491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clt\n",
      "[('Eday', 'clt'), ('day', 'clt')]\n",
      "[('day', 'clt')]\n",
      "hfls\n",
      "[('Eday', 'hfls'), ('day', 'hfls')]\n",
      "[('day', 'hfls')]\n",
      "hfss\n",
      "[('Eday', 'hfss'), ('day', 'hfss')]\n",
      "[('day', 'hfss')]\n",
      "rls\n",
      "[('Eday', 'rls'), ('day', 'rls')]\n",
      "[('day', 'rls')]\n",
      "rss\n",
      "[('Eday', 'rss'), ('day', 'rss')]\n",
      "[('day', 'rss')]\n"
     ]
    }
   ],
   "source": [
    "for variable in ['clt', 'hfls', 'hfss', 'rls', 'rss']:\n",
    "    print(variable)\n",
    "    print(new_table_mapping['APday'][variable])\n",
    "    new_table_mapping['APday'][variable] = [('day', variable)]\n",
    "    print(new_table_mapping['APday'][variable])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f4aff1",
   "metadata": {},
   "source": [
    "Retain entry from Amon with cell_methods \"area: time: mean\" rather than entry from LImon \"area: mean where land time: mean\"\n",
    "* LImon sbl ['Amon', 'LImon'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "560cdd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Amon', 'sbl'), ('LImon', 'sbl')]\n",
      "[('Amon', 'sbl')]\n"
     ]
    }
   ],
   "source": [
    "print(new_table_mapping['LImon']['sbl']) \n",
    "new_table_mapping['LImon']['sbl'] = [('Amon', 'sbl')]\n",
    "print(new_table_mapping['LImon']['sbl']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd105d",
   "metadata": {},
   "source": [
    "Entries with different pressure level sets (plev19 and plev8). Simplest option would be to suffix variable with number of pressure levels, e.g. add APday/hus19 (from Eday/hus) and APday/hus8 (from day/hus).  \n",
    "* APday hus ['Eday', 'day'] -> APday/hus19, APday/hus8\n",
    "* APday ta ['Eday', 'day'] -> APday/ta19, APday/ta8\n",
    "* APday ua ['Eday', 'day'] -> APday/ua19, APday/ua8\n",
    "* APday va ['Eday', 'day'] -> APday/va19, APday/va8\n",
    "* APday wap ['Eday', 'day'] -> APday/wap19, APday/wap8\n",
    "* APday zg ['Eday', 'day'] -> APday/zg19, APday/zg8\n",
    "* APmon hus ['Amon', 'Emon'] -> APmon/hus19, APmon/hus7h (***Note 1**)\n",
    "* APmon ua ['Amon', 'Emon'] -> APmon/ua19, APmon/ua7h (***Note 1**)\n",
    "* APmon va ['Amon', 'Emon'] -> APmon/va19, APmon/va7h (***Note 1**)\n",
    "\t\n",
    "***Note 1**: The Amon entry hadd cell methods \"time: mean\", whereas the Emon entry had \"area: time: mean\". Propose to keep the \"area: time: mean\" entry for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98e5a93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remappings = [\n",
    "    (('Eday', 'hus'), ('APday', 'hus19')),\n",
    "    (('day', 'hus'), ('APday', 'hus8')),\n",
    "    (('Eday', 'ta'), ('APday', 'ta19')),\n",
    "    (('day', 'ta'), ('APday', 'ta8')),\n",
    "    (('Eday', 'ua'), ('APday', 'ua19')),\n",
    "    (('day', 'ua'), ('APday', 'ua8')),\n",
    "    (('Eday', 'va'), ('APday', 'va19')),\n",
    "    (('day', 'va'), ('APday', 'va8')),\n",
    "    (('Eday', 'wap'), ('APday', 'wap19')),\n",
    "    (('day', 'wap'), ('APday', 'wap8')),\n",
    "    (('Eday', 'zg'), ('APday', 'zg19')),\n",
    "    (('day', 'zg'), ('APday', 'zg8')),\n",
    "    (('Amon', 'hus'), ('APmon', 'hus19')),\n",
    "    (('Emon', 'hus'), ('APmon', 'hus7h')),\n",
    "    (('Amon', 'ua'), ('APmon', 'ua19')),\n",
    "    (('Emon', 'ua'), ('APmon', 'ua7h')),\n",
    "    (('Amon', 'va'), ('APmon', 'va19')),\n",
    "    (('Emon', 'va'), ('APmon', 'va7h'))\n",
    "]\n",
    "\n",
    "for (original_table, original_variable), (new_table, new_variable) in remappings:\n",
    "    new_table_mapping[new_table][original_variable] = []\n",
    "    new_table_mapping[new_table][new_variable] = [(original_table, original_variable)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7991bb15",
   "metadata": {},
   "source": [
    "These entries have different cell methods/measures and/or grids. Propose placing appropriate entries in two MIP tables\n",
    "* APmon prsn ['Amon', 'Omon'] : \n",
    "  * Amon/prsn -> APmon/prsn (atmosphere grid, \"area: time: mean\") and \n",
    "  * Omon/prsn -> OPmon/prsn (ocean grid, \"area:mean where ice_free_sea over sea time:mean\")\n",
    "    * Set modeling_realm to ocean\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce8d2c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table_mapping['OPmon']['prsn'] = [('Omon', 'prsn')]\n",
    "mip_tables_data['Omon']['prsn']['modeling_realm'] = 'ocean'\n",
    "mip_tables_data['Omon']['prsn']['branded_variable_name'] = branded_variable_name(mip_tables_data['Omon']['prsn'])\n",
    "new_table_mapping['APmon']['prsn'] = [('Amon', 'prsn')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3012a01c",
   "metadata": {},
   "source": [
    "Sanity check: the following should give no output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79a9aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in new_tables:\n",
    "    for variable in new_tables[table]:\n",
    "        if len(new_table_mapping[table][variable]) > 1:\n",
    "            print(table, variable, new_table_mapping[table][variable])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc02ddc",
   "metadata": {},
   "source": [
    "### Additional manual changes\n",
    "\n",
    "APfxSite table doesn't seem necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de514afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'latitude': [('CFsubhr', 'latitude')],\n",
       "             'longitude': [('CFsubhr', 'longitude')]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_table_mapping['APfxSite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e98298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_table_mapping['APfxSite']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9622d004",
   "metadata": {},
   "source": [
    "## Write out to files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "697aff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(OUTPUT_LOCATION):\n",
    "    os.unlink(os.path.join(OUTPUT_LOCATION, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47def654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "header = {'data_specs_version': '6.3.0.0',\n",
    " 'cmor_version': '4.0',\n",
    " 'table_id': '<to be set>',\n",
    " 'table_date': datetime.now().strftime('%Y-%m-%d'),\n",
    " 'missing_value': '1e20',\n",
    " 'int_missing_value': '-999',\n",
    " 'product': 'model-output',\n",
    " 'approx_interval': '<NEEDS WORK>',\n",
    " 'generic_levels': '',  # overwritten if necessary\n",
    "# 'mip_era': 'CMIP6Plus',  # not to be included\n",
    " 'Conventions': 'CF-1.7 CMIP-6.3'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d04ee13-d8fb-4b74-88b6-93ef58f35878",
   "metadata": {},
   "source": [
    "Routines to set and validate checksums in JSON documents. Checksum creation and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d9f72ea-e7e6-483c-99b0-fbe4a0096319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_checksum(dictionary, overwrite=True, checksum_location='Header'):\n",
    "    \"\"\"\n",
    "    Calculate the checksum for dictionary and add it to the Header\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dictionary: dict\n",
    "        The dictionary to set the checksum for.\n",
    "    overwrite: bool\n",
    "        Overwrite the existing checksum (default True).\n",
    "    checksum_location: str\n",
    "        sub-dictionary to look for in /add the checksum to.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    RuntimeError\n",
    "        If the ``checksum`` key already exists and ``overwrite`` is\n",
    "        False.\n",
    "    \"\"\"\n",
    "    if 'checksum' in dictionary[checksum_location]:\n",
    "        if not overwrite:\n",
    "            raise RuntimeError('Checksum already exists.')\n",
    "        del dictionary[checksum_location]['checksum']\n",
    "    checksum = _checksum(dictionary)\n",
    "    dictionary[checksum_location]['checksum'] = checksum\n",
    "\n",
    "\n",
    "def validate_checksum(dictionary, checksum_location='Header'):\n",
    "    \"\"\"\n",
    "    Validate the checksum in the ``dictionary``.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dictionary: dict\n",
    "        The dictionary containing the ``checksum`` to validate.\n",
    "    checksum_location: str\n",
    "        sub-dictionary to look for in /add the checksum to.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    KeyError\n",
    "        If the ``checksum`` key does not exist.\n",
    "    RuntimeError\n",
    "        If the ``checksum`` value is invalid.\n",
    "    \"\"\"\n",
    "    if 'checksum' not in dictionary[checksum_location]:\n",
    "        raise KeyError('No checksum to validate')\n",
    "    dictionary_copy = deepcopy(dictionary)\n",
    "    del dictionary_copy[checksum_location]['checksum']\n",
    "    checksum = _checksum(dictionary_copy)\n",
    "    if dictionary[checksum_location]['checksum'] != checksum:\n",
    "        msg = ('Expected checksum   \"{}\"\\n'\n",
    "               'Calculated checksum \"{}\"').format(dictionary[checksum_location]['checksum'],\n",
    "                                                  checksum)\n",
    "        raise RuntimeError(msg)\n",
    "\n",
    "\n",
    "def _checksum(obj):\n",
    "    obj_str = json.dumps(obj, sort_keys=True)\n",
    "    checksum_hex = hashlib.md5(obj_str.encode('utf8')).hexdigest()\n",
    "    return 'md5: {}'.format(checksum_hex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "579402a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting out_name \"hus\" with \"hus7h\"\n",
      "Overwriting out_name \"ta\" with \"ta7h\"\n",
      "Overwriting out_name \"ua\" with \"ua7h\"\n",
      "Overwriting out_name \"va\" with \"va7h\"\n",
      "Overwriting out_name \"wap\" with \"wap7h\"\n",
      "Overwriting out_name \"cldicemxrat\" with \"cldicemxrat27\"\n",
      "Overwriting out_name \"cldwatmxrat\" with \"cldwatmxrat27\"\n",
      "Overwriting out_name \"grplmxrat\" with \"grplmxrat27\"\n",
      "Overwriting out_name \"hus\" with \"hus27\"\n",
      "Overwriting out_name \"hus\" with \"hus7h\"\n",
      "Overwriting out_name \"rainmxrat\" with \"rainmxrat27\"\n",
      "Overwriting out_name \"snowmxrat\" with \"snowmxrat27\"\n",
      "Overwriting out_name \"ta\" with \"ta27\"\n",
      "Overwriting out_name \"ta\" with \"ta7h\"\n",
      "Overwriting out_name \"ua\" with \"ua7h\"\n",
      "Overwriting out_name \"va\" with \"va7h\"\n",
      "Overwriting out_name \"wbptemp\" with \"wbptemp7h\"\n",
      "Overwriting out_name \"zg\" with \"zg27\"\n",
      "Overwriting out_name \"zg\" with \"zg7h\"\n",
      "Overwriting out_name \"hus\" with \"hus4\"\n",
      "Overwriting out_name \"wap\" with \"wap4\"\n",
      "Overwriting out_name \"hus\" with \"hus19\"\n",
      "Overwriting out_name \"hus\" with \"hus8\"\n",
      "Overwriting out_name \"ta\" with \"ta19\"\n",
      "Overwriting out_name \"ta\" with \"ta8\"\n",
      "Overwriting out_name \"ua\" with \"ua19\"\n",
      "Overwriting out_name \"ua\" with \"ua8\"\n",
      "Overwriting out_name \"va\" with \"va19\"\n",
      "Overwriting out_name \"va\" with \"va8\"\n",
      "Overwriting out_name \"wap\" with \"wap19\"\n",
      "Overwriting out_name \"wap\" with \"wap8\"\n",
      "Overwriting out_name \"zg\" with \"zg19\"\n",
      "Overwriting out_name \"zg\" with \"zg8\"\n",
      "Overwriting out_name \"tntrl\" with \"tntrl27\"\n",
      "Overwriting out_name \"tntrs\" with \"tntrs27\"\n",
      "Overwriting out_name \"cldicemxrat\" with \"cldicemxrat27\"\n",
      "Overwriting out_name \"cldwatmxrat\" with \"cldwatmxrat27\"\n",
      "Overwriting out_name \"grplmxrat\" with \"grplmxrat27\"\n",
      "Overwriting out_name \"hus\" with \"hus27\"\n",
      "Overwriting out_name \"rainmxrat\" with \"rainmxrat27\"\n",
      "Overwriting out_name \"snowmxrat\" with \"snowmxrat27\"\n",
      "Overwriting out_name \"ta\" with \"ta27\"\n",
      "Overwriting out_name \"tntmp\" with \"tntmp27\"\n",
      "Overwriting out_name \"ua\" with \"ua27\"\n",
      "Overwriting out_name \"va\" with \"va27\"\n",
      "Overwriting out_name \"zg\" with \"zg27\"\n",
      "Overwriting out_name \"hus\" with \"hus19\"\n",
      "Overwriting out_name \"hus\" with \"hus7h\"\n",
      "Overwriting out_name \"ua\" with \"ua19\"\n",
      "Overwriting out_name \"ua\" with \"ua7h\"\n",
      "Overwriting out_name \"va\" with \"va19\"\n",
      "Overwriting out_name \"va\" with \"va7h\"\n",
      "Overwriting out_name \"ch4\" with \"ch4Clim\"\n",
      "Overwriting out_name \"ch4global\" with \"ch4globalClim\"\n",
      "Overwriting out_name \"co2\" with \"co2Clim\"\n",
      "Overwriting out_name \"co2mass\" with \"co2massClim\"\n",
      "Overwriting out_name \"n2o\" with \"n2oClim\"\n",
      "Overwriting out_name \"n2oglobal\" with \"n2oglobalClim\"\n",
      "Overwriting out_name \"o3\" with \"o3Clim\"\n",
      "Overwriting out_name \"ta\" with \"ta27\"\n",
      "Overwriting out_name \"tntr\" with \"tntr27\"\n",
      "Overwriting out_name \"ua\" with \"ua27\"\n",
      "Overwriting out_name \"utendnogw\" with \"utendnogw27\"\n",
      "Overwriting out_name \"va\" with \"va27\"\n",
      "Overwriting out_name \"vtendnogw\" with \"vtendnogw27\"\n",
      "Overwriting out_name \"wap\" with \"wap27\"\n",
      "Overwriting out_name \"zg\" with \"zg27\"\n",
      "Overwriting out_name \"ficeberg\" with \"ficeberg2d\"\n",
      "Overwriting out_name \"hfibthermds\" with \"hfibthermds2d\"\n",
      "Overwriting out_name \"hfrunoffds\" with \"hfrunoffds2d\"\n",
      "Overwriting out_name \"hfsifrazil\" with \"hfsifrazil2d\"\n",
      "Overwriting out_name \"hfsnthermds\" with \"hfsnthermds2d\"\n",
      "Overwriting out_name \"difmxybo\" with \"difmxybo2d\"\n",
      "Overwriting out_name \"difmxylo\" with \"difmxylo2d\"\n",
      "Overwriting out_name \"diftrbbo\" with \"diftrbbo2d\"\n",
      "Overwriting out_name \"diftrblo\" with \"diftrblo2d\"\n",
      "Overwriting out_name \"diftrebo\" with \"diftrebo2d\"\n",
      "Overwriting out_name \"diftrelo\" with \"diftrelo2d\"\n",
      "Overwriting out_name \"diftrxybo\" with \"diftrxybo2d\"\n",
      "Overwriting out_name \"diftrxylo\" with \"diftrxylo2d\"\n",
      "Overwriting out_name \"dispkexyfo\" with \"dispkexyfo2d\"\n",
      "Overwriting out_name \"tnkebto\" with \"tnkebto2d\"\n"
     ]
    }
   ],
   "source": [
    "# construct new tables\n",
    "\n",
    "for table_name in new_table_mapping:\n",
    "    # header information\n",
    "    table_header = copy(header)\n",
    "    table_header['table_id'] = table_name\n",
    "    if table_name.endswith('Lev'):\n",
    "        if table_name.startswith('A'):\n",
    "            table_header['generic_levels'] = ['alevel', 'alevhalf']\n",
    "        elif table_name.startswith('O'):\n",
    "            table_header['generic_levels'] = ['olevel', 'olevhalf']\n",
    "        else:\n",
    "            # shouldn't happen\n",
    "            raise RuntimeError(table)\n",
    "    \n",
    "    # variable entries\n",
    "    variable_entry = {}\n",
    "    for variable, original_variable_list in new_table_mapping[table_name].items():\n",
    "        if len(original_variable_list) == 0:\n",
    "            # Variables that have been renamed due to conflicts, e.g. APmon/hus -> APmon/hus19 and APmon/hus7h\n",
    "            continue\n",
    "        # get name of CMIP6 mip table and variable name\n",
    "        original_mip_table, original_variable = original_variable_list[0]\n",
    "        \n",
    "        # get variable entry from original mip_tables\n",
    "        entry = copy(mip_tables_data[original_mip_table][original_variable])\n",
    "        \n",
    "        # change dimensions into a list of strings\n",
    "        entry['dimensions'] = entry['dimensions'].split()\n",
    "        # add a provenance field to indicate where this variable came from in CMIP6 (and before)\n",
    "        entry['provenance'] = {\n",
    "            'CMIP6': {\n",
    "                'mip_table': original_mip_table, \n",
    "                'variable_name': original_variable, \n",
    "                'dreq_uid': entry['dreq_uid']}}\n",
    "        # remove data request uid as independent field\n",
    "        del entry['dreq_uid']\n",
    "        # Move validation fields into a subsection\n",
    "        entry['validation'] = {}\n",
    "        for i in [\"ok_max_mean_abs\", \"ok_min_mean_abs\", \"valid_max\", \"valid_min\"]:\n",
    "            entry['validation'][i] = entry[i]\n",
    "            del entry[i]\n",
    "        \n",
    "        # overwrite outnames with variable name \n",
    "        if entry['out_name'] != variable:\n",
    "            print('Overwriting out_name \"{}\" with \"{}\"'.format(entry['out_name'], variable))\n",
    "            entry['out_name'] = variable\n",
    "                \n",
    "        variable_entry[variable] = entry\n",
    "        \n",
    "    # write out\n",
    "    new_table = {\n",
    "        'Header': table_header,\n",
    "        'variable_entry': variable_entry,\n",
    "    }\n",
    "    # Add MD5 checksum to table header\n",
    "    calculate_checksum(new_table)\n",
    "    \n",
    "    validate_checksum(new_table)\n",
    "    output_file = os.path.join(OUTPUT_LOCATION, '{}.json'.format(table_name))\n",
    "    \n",
    "    with open(output_file, 'w') as file_handle:\n",
    "        json.dump(new_table, file_handle, indent=2, sort_keys=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9057ec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Header\": {\n",
      "    \"Conventions\": \"CF-1.7 CMIP-6.3\",\n",
      "    \"approx_interval\": \"<NEEDS WORK>\",\n",
      "    \"checksum\": \"md5: 6a2da2bd3b93327ca0cc89b3543294a8\",\n",
      "    \"cmor_version\": \"4.0\",\n",
      "    \"data_specs_version\": \"6.3.0.0\",\n",
      "    \"generic_levels\": \"\",\n",
      "    \"int_missing_value\": \"-999\",\n",
      "    \"missing_value\": \"1e20\",\n",
      "    \"product\": \"model-output\",\n",
      "    \"table_date\": \"2022-09-05\",\n",
      "    \"table_id\": \"ACmon\"\n",
      "  },\n",
      "  \"variable_entry\": {\n",
      "    \"flashrate\": {\n",
      "      \"branded_variable_name\": \"flashrate_mon-ac-tav-z0-hxy\",\n",
      "      \"cell_measures\": \"area: areacella\",\n",
      "      \"cell_methods\": \"area: time: mean\",\n",
      "      \"comment\": \"proposed name: lightning_flash_rate (units to be interpreted as 'counts km-2 s-1)\",\n",
      "      \"dimensions\": [\n",
      "        \"longitude\",\n",
      "        \"latitude\",\n",
      "        \"time\"\n",
      "      ],\n",
      "      \"frequency\": \"mon\",\n",
      "      \"long_name\": \"Lightning Flash Rate\",\n",
      "      \"modeling_realm\": \"atmosChem\",\n",
      "      \"out_name\": \"flashrate\",\n",
      "      \"positive\": \"\",\n",
      "      \"provenance\": {\n",
      "        \"CMIP6\": {\n",
      "          \"dreq_uid\": \"6f691c58-9acb-11e6-b7ee-ac72891c3257\",\n",
      "          \"mip_table\": \"Emon\",\n",
      "          \"variable_name\": \"flashrate\"\n",
      "        }\n",
      "      },\n",
      "      \"standard_name\": \"frequency_of_lightning_flashes_per_unit_area\",\n",
      "      \"type\": \"real\",\n",
      "      \"units\": \"km-2 s-1\",\n",
      "      \"validation\": {\n",
      "        \"ok_max_mean_abs\": \"\",\n",
      "        \"ok_min_mean_abs\": \"\",\n",
      "        \"valid_max\": \"\",\n",
      "        \"valid_min\": \"\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat ../../Tables/ACmon.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3b527e",
   "metadata": {},
   "source": [
    "Copy over formula terms and coordinates\n",
    "*Question: is there value in adding MD5 sums here?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17c51f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../Tables/coordinate.json'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "shutil.copy(os.path.join(CMIP6_LOCATION, 'CMIP6_formula_terms.json'), os.path.join(OUTPUT_LOCATION, 'formula_terms.json'))\n",
    "shutil.copy(os.path.join(CMIP6_LOCATION, 'CMIP6_coordinate.json'), os.path.join(OUTPUT_LOCATION, 'coordinate.json'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1135cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grids file\n",
    "\n",
    "# Load grid file\n",
    "grids_file = os.path.join(CMIP6_LOCATION, 'CMIP6_grids.json')\n",
    "with open(grids_file) as grids_fh:\n",
    "    grids_data = json.load(grids_fh)\n",
    "\n",
    "# tweak header used for MIP table\n",
    "grids_data['Header'] = header\n",
    "grids_data['Header']['table_id'] = 'grids'\n",
    "for f in ['generic_levels', 'approx_interval']:\n",
    "    if f in grids_data:\n",
    "        del grids_data['Header'][f]\n",
    "\n",
    "calculate_checksum(grids_data)\n",
    "        \n",
    "# write out\n",
    "output_grids_file = os.path.join(OUTPUT_LOCATION, 'grids.json')\n",
    "with open(output_grids_file, 'w') as grids_fh:\n",
    "    json.dump(grids_data, grids_fh, indent=2, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "410b1c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Header': {'data_specs_version': '6.3.0.0',\n",
       "  'cmor_version': '4.0',\n",
       "  'table_id': 'grids',\n",
       "  'table_date': '2022-09-05',\n",
       "  'missing_value': '1e20',\n",
       "  'int_missing_value': '-999',\n",
       "  'product': 'model-output',\n",
       "  'approx_interval': '<NEEDS WORK>',\n",
       "  'generic_levels': '',\n",
       "  'Conventions': 'CF-1.7 CMIP-6.3',\n",
       "  'checksum': 'md5: 39e7a038c812a390fc0e412653363015'},\n",
       " 'mapping_entry': {'sample_user_mapping': {'parameter1': 'false_easting',\n",
       "   'parameter2': 'false_northing',\n",
       "   'coordinates': 'rlon rlat'}},\n",
       " 'axis_entry': {'grid_latitude': {'standard_name': 'grid_latitude',\n",
       "   'units': 'degrees',\n",
       "   'axis': 'Y',\n",
       "   'long_name': 'latitude in rotated pole grid',\n",
       "   'out_name': 'rlat',\n",
       "   'type': 'double'},\n",
       "  'grid_longitude': {'standard_name': 'grid_longitude',\n",
       "   'units': 'degrees',\n",
       "   'axis': 'X',\n",
       "   'long_name': 'longitude in rotated pole grid',\n",
       "   'out_name': 'rlon',\n",
       "   'type': 'double'},\n",
       "  'i_index': {'standard_name': '',\n",
       "   'units': '1',\n",
       "   'axis': '',\n",
       "   'long_name': 'first spatial index for variables stored on an unstructured grid',\n",
       "   'out_name': 'i',\n",
       "   'type': 'integer'},\n",
       "  'j_index': {'standard_name': '',\n",
       "   'units': '1',\n",
       "   'axis': '',\n",
       "   'long_name': 'second spatial index for variables stored on an unstructured grid',\n",
       "   'out_name': 'j',\n",
       "   'type': 'integer'},\n",
       "  'k_index': {'standard_name': '',\n",
       "   'units': '1',\n",
       "   'axis': '',\n",
       "   'long_name': 'third spatial index for variables stored on an unstructured grid',\n",
       "   'out_name': 'k',\n",
       "   'type': 'integer'},\n",
       "  'l_index': {'standard_name': '',\n",
       "   'units': '1',\n",
       "   'axis': '',\n",
       "   'long_name': 'fourth spatial index for variables stored on an unstructured grid',\n",
       "   'out_name': 'l',\n",
       "   'type': 'integer'},\n",
       "  'm_index': {'standard_name': '',\n",
       "   'units': '1',\n",
       "   'axis': '',\n",
       "   'long_name': 'fifth spatial index for variables stored on an unstructured grid',\n",
       "   'out_name': 'm',\n",
       "   'type': 'integer'},\n",
       "  'vertices': {'standard_name': '',\n",
       "   'units': '',\n",
       "   'axis': '',\n",
       "   'long_name': '',\n",
       "   'out_name': '',\n",
       "   'type': ''},\n",
       "  'x': {'standard_name': 'projection_x_coordinate',\n",
       "   'units': 'm',\n",
       "   'axis': 'X',\n",
       "   'long_name': 'x coordinate of projection',\n",
       "   'out_name': '',\n",
       "   'type': 'double'},\n",
       "  'x_deg': {'standard_name': 'projection_x_coordinate',\n",
       "   'units': 'degrees',\n",
       "   'axis': 'X',\n",
       "   'long_name': 'x coordinate of projection',\n",
       "   'out_name': 'x',\n",
       "   'type': 'double'},\n",
       "  'y': {'standard_name': 'projection_y_coordinate',\n",
       "   'units': 'm',\n",
       "   'axis': 'Y',\n",
       "   'long_name': 'y coordinate of projection',\n",
       "   'out_name': '',\n",
       "   'type': 'double'},\n",
       "  'y_deg': {'standard_name': 'projection_y_coordinate',\n",
       "   'units': 'degrees',\n",
       "   'axis': 'Y',\n",
       "   'long_name': 'y coordinate of projection',\n",
       "   'out_name': 'y',\n",
       "   'type': 'double'}},\n",
       " 'variable_entry': {'latitude': {'standard_name': 'latitude',\n",
       "   'units': 'degrees_north',\n",
       "   'long_name': 'latitude',\n",
       "   'dimensions': 'longitude latitude',\n",
       "   'out_name': 'latitude',\n",
       "   'valid_min': '-90.0',\n",
       "   'valid_max': '90.0',\n",
       "   'type': 'double'},\n",
       "  'longitude': {'standard_name': 'longitude',\n",
       "   'units': 'degrees_east',\n",
       "   'long_name': 'longitude',\n",
       "   'dimensions': 'longitude latitude',\n",
       "   'out_name': 'longitude',\n",
       "   'valid_min': '0.0',\n",
       "   'valid_max': '360.0',\n",
       "   'type': 'double'},\n",
       "  'vertices_latitude': {'standard_name': '',\n",
       "   'units': 'degrees_north',\n",
       "   'long_name': '',\n",
       "   'dimensions': 'vertices longitude latitude',\n",
       "   'out_name': 'vertices_latitude',\n",
       "   'valid_min': '-90.0',\n",
       "   'valid_max': '90.0',\n",
       "   'type': 'double'},\n",
       "  'vertices_longitude': {'standard_name': '',\n",
       "   'units': 'degrees_east',\n",
       "   'long_name': '',\n",
       "   'dimensions': 'vertices longitude latitude',\n",
       "   'out_name': 'vertices_longitude',\n",
       "   'valid_min': '0.0',\n",
       "   'valid_max': '360.0',\n",
       "   'type': 'double'}}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grids_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb5c4db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick required pieces out of CV file\n",
    "cv_file = os.path.join(CMIP6_LOCATION, 'CMIP6_CV.json')\n",
    "\n",
    "# load data, but drop the top level 'CV' section\n",
    "with open(cv_file) as cf_handle:\n",
    "    cv_data = json.load(cf_handle)['CV']\n",
    "\n",
    "keys_to_keep_in_general_cvs = [\n",
    "    # 'required_global_attributes',\n",
    "    'version_metadata',\n",
    "    'institution_id',  \n",
    "    'source_type',\n",
    "    'frequency',\n",
    "    'grid_label',\n",
    "    'nominal_resolution',\n",
    "    'realm',\n",
    "    'table_id',\n",
    "    'product',\n",
    "    # 'tracking_id',     \n",
    "    # 'further_info_url', # ?\n",
    "    'realization_index',\n",
    "    'variant_label',\n",
    "    'data_specs_version',\n",
    "    'Conventions',\n",
    "    'forcing_index',\n",
    "    'initialization_index',\n",
    "    'physics_index'\n",
    "]\n",
    "# construct dictionary with required keys\n",
    "generic_cv_data = {\n",
    "    i: copy(cv_data[i]) for i in keys_to_keep_in_general_cvs\n",
    "}\n",
    "project_cv_data = {\n",
    "    i: copy(cv_data[i]) for i in cv_data if i not in keys_to_keep_in_general_cvs\n",
    "}   \n",
    "\n",
    "# Update version metadata\n",
    "generic_cv_data['version_metadata'] = {\n",
    "    'CV_collection_modified': datetime.now().strftime('%Y-%m-%d'),\n",
    "    'CV_collection_version': '6.3.0.0',\n",
    "    'author': 'Matt Mizielinski <matthew.mizielinski@metoffice.gov.uk>',\n",
    "    'institution_id': 'MOHC',\n",
    "    'previous_commit': 'To be added',\n",
    "    'specs_doc': 'v6.3.0 (link TBC)'\n",
    "}\n",
    "project_cv_data['version_metadata'] = {\n",
    "    'CV_collection_modified': datetime.now().strftime('%Y-%m-%d'),\n",
    "    'CV_collection_version': '6.3.0.0',\n",
    "    'author': 'Matt Mizielinski <matthew.mizielinski@metoffice.gov.uk>',\n",
    "    'institution_id': 'MOHC',\n",
    "    'previous_commit': 'To be added',\n",
    "    'specs_doc': 'v6.3.0 (link TBC)'\n",
    "}\n",
    "\n",
    "# update list of tables\n",
    "generic_cv_data['table_id'] = sorted(list(new_tables.keys()))\n",
    "\n",
    "# Repurpose data_specs_version\n",
    "# Allow (1 or 2 digits).(1 or 2 digits).(1-3 digits).(1-3 digits), e.g. 6.3.20.119\n",
    "# use 6.3 to indicate that this is post CMIP6 (6.2) use third index for new groups of variables and fourth for variable updates\n",
    "generic_cv_data['data_specs_version'] = ['^[[:digit:]]\\\\{1,2\\\\}\\\\.[[:digit:]]\\\\{1,2\\\\}\\\\.[[:digit:]]\\\\{1,3\\\\}\\\\.[[:digit:]]\\\\{1,3\\\\}$']\n",
    "\n",
    "generic_cv_data['Conventions'] = ['^CF-1.7 CMIP-6.[0-3]\\\\( UGRID-1.0\\\\)\\\\{0,\\\\}$']\n",
    "\n",
    "# update CMIP6Plus CVs\n",
    "\n",
    "project_cv_data['DRS']['directory_path_example'].replace('CMIP6', 'CMIP6Plus')\n",
    "project_cv_data['DRS']['directory_path_sub_experiment_example'].replace('CMIP6', 'CMIP6Plus')\n",
    "project_cv_data['license'][0].replace('CMIP6', 'CMIP6Plus')\n",
    "project_cv_data['mip_era'] = 'CMIP6Plus'\n",
    "\n",
    "# Write out\n",
    "\n",
    "calculate_checksum(generic_cv_data, checksum_location='version_metadata')\n",
    "calculate_checksum(project_cv_data, checksum_location='version_metadata')\n",
    "\n",
    "with open(os.path.join(OUTPUT_LOCATION, 'generic_CV.json'), 'w') as cv_fh:\n",
    "    json.dump(generic_cv_data, cv_fh, indent=2, sort_keys=True)\n",
    "with open(os.path.join(OUTPUT_LOCATION, 'CMIP6Plus_CV.json'), 'w') as cv_fh:\n",
    "    json.dump(project_cv_data, cv_fh, indent=2, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29e00b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACmon.json',\n",
       " 'ACmonZ.json',\n",
       " 'AE1hr.json',\n",
       " 'AE3hrPt.json',\n",
       " 'AE3hrPtLev.json',\n",
       " 'AE6hr.json',\n",
       " 'AE6hrPt.json',\n",
       " 'AE6hrPtLev.json',\n",
       " 'AEday.json',\n",
       " 'AEmon.json',\n",
       " 'AEmonLev.json',\n",
       " 'AEmonZ.json',\n",
       " 'AEsubhrPt.json',\n",
       " 'AEsubhrPtSite.json',\n",
       " 'AP1hr.json',\n",
       " 'AP1hrPt.json',\n",
       " 'AP3hr.json',\n",
       " 'AP3hrPt.json',\n",
       " 'AP3hrPtLev.json',\n",
       " 'AP6hr.json',\n",
       " 'AP6hrPt.json',\n",
       " 'AP6hrPtLev.json',\n",
       " 'AP6hrPtZ.json',\n",
       " 'APday.json',\n",
       " 'APdayLev.json',\n",
       " 'APdayZ.json',\n",
       " 'APfx.json',\n",
       " 'APmon.json',\n",
       " 'APmonClim.json',\n",
       " 'APmonClimLev.json',\n",
       " 'APmonDiurnal.json',\n",
       " 'APmonLev.json',\n",
       " 'APmonZ.json',\n",
       " 'APsubhrPt.json',\n",
       " 'APsubhrPtLev.json',\n",
       " 'APsubhrPtSite.json',\n",
       " 'CMIP6Plus_CV.json',\n",
       " 'GIAfx.json',\n",
       " 'GIAmon.json',\n",
       " 'GIAyr.json',\n",
       " 'GIGfx.json',\n",
       " 'GIGmon.json',\n",
       " 'GIGyr.json',\n",
       " 'LI3hrPt.json',\n",
       " 'LI6hrPt.json',\n",
       " 'LIday.json',\n",
       " 'LIfx.json',\n",
       " 'LImon.json',\n",
       " 'LIsubhrPtSite.json',\n",
       " 'LP3hr.json',\n",
       " 'LP3hrPt.json',\n",
       " 'LP6hrPt.json',\n",
       " 'LPday.json',\n",
       " 'LPfx.json',\n",
       " 'LPmon.json',\n",
       " 'LPyr.json',\n",
       " 'LPyrPt.json',\n",
       " 'OBday.json',\n",
       " 'OBmon.json',\n",
       " 'OBmonLev.json',\n",
       " 'OByr.json',\n",
       " 'OByrLev.json',\n",
       " 'OP3hrPt.json',\n",
       " 'OPday.json',\n",
       " 'OPdec.json',\n",
       " 'OPdecLev.json',\n",
       " 'OPdecZ.json',\n",
       " 'OPfx.json',\n",
       " 'OPmon.json',\n",
       " 'OPmonClim.json',\n",
       " 'OPmonClimLev.json',\n",
       " 'OPmonLev.json',\n",
       " 'OPmonZ.json',\n",
       " 'OPyr.json',\n",
       " 'OPyrLev.json',\n",
       " 'SIday.json',\n",
       " 'SImon.json',\n",
       " 'SImonPt.json',\n",
       " 'coordinate.json',\n",
       " 'formula_terms.json',\n",
       " 'generic_CV.json',\n",
       " 'grids.json']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(os.listdir(OUTPUT_LOCATION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524ba412-8d7d-42e8-86fe-ae2d5215ff5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default-current",
   "language": "python",
   "name": "default-current"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
